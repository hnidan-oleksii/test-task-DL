{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8212cba3-c99b-4839-9637-40d62c9c95e7",
   "metadata": {},
   "source": [
    "## Run model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "02549eae-e2a0-4ad5-9ecf-11243a05ef00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-01-20 22:14:19,296 - INFO - Using device: cuda\n",
      "2025-01-20 22:14:19,512 - INFO - Model initialized successfully\n",
      "Map: 100%|█████████████████████████| 7388/7388 [00:00<00:00, 9877.86 examples/s]\n",
      "Map: 100%|████████████████████████| 1599/1599 [00:00<00:00, 11527.23 examples/s]\n",
      "Epoch 1/10:   0%|                                       | 0/462 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 1/10: 100%|██████████████████| 462/462 [01:13<00:00,  6.25it/s, loss=0.17]\n",
      "Evaluating: 100%|██████| 100/100 [00:05<00:00, 19.37it/s, loss=0.134, acc=0.939]\n",
      "2025-01-20 22:15:42,328 - INFO - Model saved to best_model\n",
      "2025-01-20 22:15:42,328 - INFO - Epoch 1/10 - Train Loss: 0.1657, Val Loss: 0.1115, Val Accuracy: 0.9590\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 2/10: 100%|████████████████| 462/462 [01:14<00:00,  6.22it/s, loss=0.0358]\n",
      "Evaluating: 100%|██████| 100/100 [00:05<00:00, 19.36it/s, loss=0.182, acc=0.951]\n",
      "2025-01-20 22:17:02,429 - INFO - Model saved to best_model\n",
      "2025-01-20 22:17:02,429 - INFO - Epoch 2/10 - Train Loss: 0.0884, Val Loss: 0.1044, Val Accuracy: 0.9630\n",
      "Epoch 3/10:   0%|                                       | 0/462 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 3/10: 100%|████████████████| 462/462 [01:14<00:00,  6.22it/s, loss=0.0446]\n",
      "Evaluating: 100%|██████| 100/100 [00:05<00:00, 19.44it/s, loss=0.206, acc=0.946]\n",
      "2025-01-20 22:18:21,868 - INFO - Epoch 3/10 - Train Loss: 0.0596, Val Loss: 0.1088, Val Accuracy: 0.9657\n",
      "Epoch 4/10:   0%|                                       | 0/462 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 4/10: 100%|███████████████| 462/462 [01:14<00:00,  6.22it/s, loss=0.00943]\n",
      "Evaluating: 100%|██████| 100/100 [00:05<00:00, 19.33it/s, loss=0.211, acc=0.958]\n",
      "2025-01-20 22:19:41,358 - INFO - Epoch 4/10 - Train Loss: 0.0412, Val Loss: 0.1184, Val Accuracy: 0.9648\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 5/10: 100%|███████████████| 462/462 [01:14<00:00,  6.19it/s, loss=0.00759]\n",
      "Evaluating: 100%|███████| 100/100 [00:05<00:00, 19.17it/s, loss=0.24, acc=0.959]\n",
      "2025-01-20 22:21:01,262 - INFO - Epoch 5/10 - Train Loss: 0.0283, Val Loss: 0.1321, Val Accuracy: 0.9660\n",
      "Epoch 6/10:   0%|                                       | 0/462 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 6/10: 100%|████████████████| 462/462 [01:14<00:00,  6.17it/s, loss=0.0387]\n",
      "Evaluating: 100%|██████| 100/100 [00:05<00:00, 19.13it/s, loss=0.258, acc=0.959]\n",
      "2025-01-20 22:22:21,423 - INFO - Epoch 6/10 - Train Loss: 0.0210, Val Loss: 0.1473, Val Accuracy: 0.9652\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 7/10: 100%|███████████████| 462/462 [01:14<00:00,  6.17it/s, loss=0.00331]\n",
      "Evaluating: 100%|██████| 100/100 [00:05<00:00, 19.29it/s, loss=0.273, acc=0.956]\n",
      "2025-01-20 22:23:41,474 - INFO - Epoch 7/10 - Train Loss: 0.0150, Val Loss: 0.1526, Val Accuracy: 0.9659\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 8/10: 100%|████████████████| 462/462 [01:14<00:00,  6.17it/s, loss=0.0044]\n",
      "Evaluating: 100%|██████| 100/100 [00:05<00:00, 19.33it/s, loss=0.284, acc=0.958]\n",
      "2025-01-20 22:25:01,470 - INFO - Epoch 8/10 - Train Loss: 0.0121, Val Loss: 0.1639, Val Accuracy: 0.9651\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 9/10: 100%|████████████████| 462/462 [01:14<00:00,  6.20it/s, loss=0.0024]\n",
      "Evaluating: 100%|██████| 100/100 [00:05<00:00, 19.17it/s, loss=0.289, acc=0.959]\n",
      "2025-01-20 22:26:21,220 - INFO - Epoch 9/10 - Train Loss: 0.0096, Val Loss: 0.1667, Val Accuracy: 0.9658\n",
      "Epoch 10/10:   0%|                                      | 0/462 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 10/10: 100%|██████████████| 462/462 [01:14<00:00,  6.19it/s, loss=0.00405]\n",
      "Evaluating: 100%|██████| 100/100 [00:05<00:00, 19.26it/s, loss=0.299, acc=0.959]\n",
      "2025-01-20 22:27:41,096 - INFO - Epoch 10/10 - Train Loss: 0.0081, Val Loss: 0.1718, Val Accuracy: 0.9659\n",
      "2025-01-20 22:27:41,746 - INFO - Model saved to ./model\n",
      "2025-01-20 22:27:41,746 - INFO - Model training completed and saved to ./model\n"
     ]
    }
   ],
   "source": [
    "!python train.py --train_set_path ./data/train \\\n",
    "                 --val_set_path ./data/val \\\n",
    "                 --model_path ./model \\\n",
    "                 --epochs 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e0d684-2644-4de1-906e-c6fdd3d84e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f519e2d-6176-45be-96ac-29cbb53fde36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "64b2ae28-890c-4461-b503-4793892c2d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c594cded8c6cc21\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c594cded8c6cc21\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53fd31a-20fe-4f28-af44-86b269a01fe1",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "dbb0ba57-4b02-4a8d-bfa3-f4b4ba63fc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-01-20 22:47:55,367 - INFO - Using device: cuda\n",
      "2025-01-20 22:47:56,115 - INFO - Model saved to ./best_model\n",
      "2025-01-20 22:47:56,115 - INFO - Model loaded successfully\n",
      "2025-01-20 22:47:56,116 - INFO - Loaded 1611 texts\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:06<00:00,  1.15it/s]\n",
      "2025-01-20 22:48:02,295 - INFO - Predictions saved to ./data/preds\n"
     ]
    }
   ],
   "source": [
    "!python inference.py --model_path ./best_model \\\n",
    "                     --input_path ./data/test_text \\\n",
    "                     --output_path ./data/preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a374f8-77f9-44d3-8ad6-ca1956e7ae0f",
   "metadata": {},
   "source": [
    "## Read the test data\n",
    "`test_texts` - list of sentences from test portion\n",
    "\n",
    "`test_labels` - list of labels from test portion\n",
    "\n",
    "`preds` - list of dictionaries with predictions. Each dict contains the following lists:\n",
    "* `text` - list with the words from the sentence \\\n",
    "* `labels` - list with labels of the corresponding words \\\n",
    "* `word_label` - list of word-label pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7903cf3d-fa6e-43a7-9855-1dfda96039ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "test_texts_path = './data/test_text'\n",
    "test_labels_path = './data/test_labels'\n",
    "preds_path = './data/preds'\n",
    "\n",
    "with open(test_texts_path, 'r', encoding='utf-8') as f:\n",
    "    test_texts = [line for line in f]\n",
    "    \n",
    "with open(test_labels_path, 'r', encoding='utf-8') as f:\n",
    "    test_labels = [line.strip().split() for line in f]\n",
    "    \n",
    "with open(preds_path, 'r', encoding='utf-8') as f:\n",
    "    preds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8075d34f-7c3d-4204-8fb5-e4ca3199eeee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Cerro', 'B-MOUNTAIN'],\n",
       " ['Chirrip', 'I-MOUNTAIN'],\n",
       " ['is', 'O'],\n",
       " ['the', 'O'],\n",
       " ['highest', 'O'],\n",
       " ['mountain', 'O'],\n",
       " ['in', 'O'],\n",
       " ['Costa', 'O'],\n",
       " ['Rica', 'O'],\n",
       " [',', 'O'],\n",
       " ['with', 'O'],\n",
       " ['an', 'O'],\n",
       " ['elevation', 'O'],\n",
       " ['of', 'O'],\n",
       " ['3820', 'O'],\n",
       " ['metres', 'O'],\n",
       " ['.', 'O']]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = [pred['labels'] for pred in preds]\n",
    "preds[2]['word_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "28e23b04-c660-4e90-ac72-bc46675650b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8401 \n",
      "Recall: 0.8323\n"
     ]
    }
   ],
   "source": [
    "labels_to_check = {'B-MOUNTAIN', 'I-MOUNTAIN'}\n",
    "total_labels = 0\n",
    "found_correct_labels = 0\n",
    "misclassified_labels = 0\n",
    "\n",
    "for true, pred in zip(test_labels, predicted_labels):\n",
    "    # ground truth labels need to be identified\n",
    "    total_labels += sum(1 for t in true if t in labels_to_check)\n",
    "    \n",
    "    # correctly predicted mountain labels\n",
    "    found_correct_labels += sum(1 for t, p in zip(true, pred) if t in labels_to_check and t == p)\n",
    "    \n",
    "    # misclassified labels (predicted as mountain but ground truth is different)\n",
    "    misclassified_labels += sum(1 for t, p in zip(true, pred) if p in labels_to_check and t != p)\n",
    "\n",
    "precision = found_correct_labels / (found_correct_labels + misclassified_labels) if (found_correct_labels + misclassified_labels) > 0 else 0\n",
    "recall = found_correct_labels / total_labels if total_labels > 0 else 0\n",
    "\n",
    "print(f\"Precision: {precision:.4f} \\nRecall: {recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
